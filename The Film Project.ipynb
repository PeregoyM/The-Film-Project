{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import pandas as pd                     # data frames\n",
    "import numpy as np                      # ndarrays\n",
    "import requests as rq                   # http requests\n",
    "from bs4 import BeautifulSoup as soup   # beautiful soup for parsing\n",
    "import regex as re                      # regex operations\n",
    "from plotnine import *                  # descriptive plotting\n",
    "from datetime import datetime as dt     # manipulating datetime types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this requests the data on Movie Production Companies sorted by Worldwide Box Office, high->low\n",
    "num_url = 'https://www.the-numbers.com/movies/production-companies/#production_companies_overview=od3'\n",
    "num_rq = rq.get(num_url)\n",
    "num_soup = soup(num_rq.text, 'lxml') # use 'lxml' instead of 'html.parser' -> problems avoided\n",
    "\n",
    "ls = []                           # for storing entries and will be converted to data frame\n",
    "body = num_soup.find('tbody')     # find beginning of useful data\n",
    "trs = body.findAll('tr')          # extract all html <tbody> row entries \n",
    "for entry in trs:                 # each row \n",
    "    a = entry.find('a')['href']   # find link of each production company -> used to get all movies later\n",
    "    a = a[26:]                    # remove excessive URL information -> hard code is ugly, but more concise\n",
    "    x = entry.text.split('\\n')    # get all entry data -> company name, movies made, US Boxoffice, Worldwide\n",
    "    x = x[1:len(x)-1]             # trim data of two empty entries\n",
    "    r = [a]                       # it has to be like this... even the separate rows\n",
    "    r.extend(x)\n",
    "    ls.append(r)                  # try to clearn this before final submission\n",
    "\n",
    "numbers = pd.DataFrame(ls, columns=['Link','Company','No.of Movies','Domestic','Worldwide']) # create data frame\n",
    "\n",
    "# Clean Data :\n",
    "# - use regex to convert Number's format to int\n",
    "# - compute International Box Office by subtracting Worldwide from Domestic \n",
    "numbers[numbers.columns[3:]] = numbers[numbers.columns[3:]].replace(r'[$,*]', '', regex=True).astype(int)\n",
    "numbers['International'] = numbers['Worldwide'] - numbers['Domestic'] # compute US-International Box Office"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor EDA\n",
    "\n",
    "- note: our data isn't too accurate yet, and does not really answer the main question\n",
    "- world wide vs. domestic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for expansion\n",
    "what are a few graphs I could explore with a group to\n",
    "- generate interest\n",
    "- indicate that more search is needed and possible\n",
    "\n",
    "\n",
    "how accurate is this data? \n",
    "\n",
    "- when does $0 Worldwide become common? \n",
    "- near the bottom, we see that most companies have no profit. \n",
    "- inspect individual companies\n",
    "- lots of missing data, but consistant sales reported\n",
    "- why? not many production companies make their budgets public\n",
    "- lets use the links from earlier to build a more accurate data frame\n",
    "\n",
    "A note on film budgets\n",
    "- the buget information that we really want is spare data, and not easily found\n",
    "- I mean data on how much the props department was paid, how much the director was paid, the marketing staff, electricians, extra, each main actor, the producers\n",
    "- this data could be much more insightful, allowing a breakdown of directors' success rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve more accurate data\n",
    "\n",
    "After determining how to limit our requests (~14k is too much and irrelevant),\n",
    "for every company considered, we will request the data from their individual file.\n",
    "That individual file contains information on every film for each production company.\n",
    "\n",
    "This is the data we want. There is budget information, date information (for normalizing) and we can drop\n",
    "incomplete rows from consideration. Overall, this is an improvement in accuracy (perhaps measured later?)\n",
    "- measure calculated sum which drops incomplete entries against the given sums on the main page\n",
    "\n",
    "\n",
    "## Questions for expansion\n",
    "what are a few graphs I could explore with a group to\n",
    "- generate interest\n",
    "- indicate that more search is needed and possible\n",
    "\n",
    "how accurate is this data? \n",
    "- when does $0 Worldwide become common? \n",
    "- near the bottom, we see that most companies have no profit. \n",
    "- inspect individual companies\n",
    "- lots of missing data, but consistant sales reported\n",
    "- why? not many production companies make their budgets public\n",
    "- lets use the links from earlier to build a more accurate data frame\n",
    "\n",
    "A note on film budgets\n",
    "- the buget information that we really want is spare data, and not easily found\n",
    "- I mean data on how much the props department was paid, how much the director was paid, the marketing staff, electricians, extra, each main actor, the producers\n",
    "- this data could be much more insightful, allowing a breakdown of directors' success rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-7c73b999ffa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# type cast monetary info as int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'International'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Worldwide'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Domestic'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# compute International box office\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'requests skipped : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbad_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\ntime : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# this base URL is a route for each company\n",
    "base_url = \"https://www.the-numbers.com/movies/production-company\"\n",
    "all_entries = []\n",
    "top1000 = numbers.head(1000)\n",
    "\n",
    "# incoming data needs to be properly treated with regex -> returns list (empty or ready for entry)\n",
    "# - separate Date and Film Title\n",
    "# - separete budget, opening weekend, domestic, worldwide\n",
    "# - regect all entries of inappropriate size\n",
    "\n",
    "def treat_data(entry):\n",
    "    ret = []\n",
    "    t = entry.text\n",
    "    x = re.split(r'(\\w+\\s\\d+,\\s\\d{4})',t)[1:]\n",
    "    if x :                                         # IF date is found\n",
    "        date = dt.strptime(x[0],'%b %d, %Y').date()   # extract date with regex\n",
    "        info = re.split(r'\\n',x[1:][0])               \n",
    "        title = info[0]                               # extract title\n",
    "        money = re.split(r'\\$',info[1])[1:]           # extract all monetary information\n",
    "        if len(money) == 4:                           # IF all monetary information is accounted\n",
    "            money = [re.sub(r',','',m) for m in money]\n",
    "            ret.append(date)                            # add date\n",
    "            ret.append(title)                           # add title\n",
    "            for m in money: ret.append(m)               # add all money\n",
    "    return ret                                     # return list, empty or accurate\n",
    "\n",
    "t1 = dt.now()\n",
    "for link,comp in zip(top1000.Link, top1000.Company): # for each entry in data frame\n",
    "    full_url = base_url + link        # consruct full link using base\n",
    "    r = rq.get(full_url)        # request full link\n",
    "    if r.status_code == 200:    # IF status return is good\n",
    "        SOUP = soup(r.text, 'lxml') # make soup\n",
    "        body = SOUP.find('tbody')         # find beginning of useful data\n",
    "        trs = body.findAll('tr')          # extract all <tr> html tags \n",
    "        for entry in trs:                 # each each row entry \n",
    "            x = treat_data(entry)            # treat data, returning [] if data is insufficient\n",
    "            if x != []:                      # if data is good\n",
    "                all_entries.append([comp]+x) # add company specific entry to total entries\n",
    "    else: bad_status += 1\n",
    "                \n",
    "df = pd.DataFrame(all_entries, columns=['Company','Release Date','Film Title',     # film info\n",
    "                                        'Budget','Opening','Domestic','Worldwide'] # monetary info\n",
    "                 )\n",
    "df[df.columns[3:]] = df[df.columns[3:]].astype(int)     # type cast monetary info as int\n",
    "df['International'] = df['Worldwide'] - df['Domestic']  # compute International box office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DATA SOURCE\n",
    "\n",
    "# omdb    - online movie database on individual films\n",
    "# numbers - monetary production data on production companies and films\n",
    "\n",
    "# end with two dataframes\n",
    "# - omdb .... hmmm\n",
    "# - numbers main page sorted by highest worldwide\n",
    "\n",
    "# EXPAND ON CURRENT DATA\n",
    "# omdb\n",
    "# - for each production company on the main page\n",
    "#      + save the company name\n",
    "#      + http request the associated link\n",
    "#      + create a data frame for all the movies with their budgets\n",
    "#      + append this data to the master dataframe where all movies with their budgets and production companies are listed\n",
    "\n",
    "# - rename to Domestic to US-Domestic\n",
    "# - create new column for US-International = (WorldWide - US)\n",
    "# - create column for Profit Margin = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
